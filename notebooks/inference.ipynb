{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from fastspeech2.utils.utils import *\n",
                "from fastspeech2.trainer.trainer import *\n",
                "from fastspeech2.model.fastspeech import *\n",
                "from fastspeech2.loss.loss import *\n",
                "from fastspeech2.datasets.lj_speech import *\n",
                "from fastspeech2.collate_fn.collate_fn import *\n",
                "from fastspeech2.utils.utils import *\n",
                "from fastspeech2.logger.wandb_writer import *\n",
                "import torch\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import DataLoader\n",
                "from torch.optim.lr_scheduler import OneCycleLR\n",
                "from dataclasses import dataclass\n",
                "from configs.base_config import *\n",
                "from text import text_to_sequence\n",
                "\n",
                "from vocoder import utils\n",
                "from vocoder import audio\n",
                "from vocoder import waveglow"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "mel_config = MelSpectrogramConfig()\n",
                "model_config = FastSpeechConfig()\n",
                "train_config = TrainConfig()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model = FastSpeech(model_config, mel_config, train_config)\n",
                "model = model.to(train_config.device)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "WaveGlow = utils.get_WaveGlow()\n",
                "WaveGlow = WaveGlow.cuda()\n",
                "\n",
                "model.load_state_dict(torch.load('../model_new/checkpoint_225000.pth.tar', map_location='cuda:0')['model'])\n",
                "model = model.eval()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def synthesis(model, text, alpha=1.0):\n",
                "    text = np.array(phn)\n",
                "    text = np.stack([text])\n",
                "    src_pos = np.array([i+1 for i in range(text.shape[1])])\n",
                "    src_pos = np.stack([src_pos])\n",
                "    sequence = torch.from_numpy(text).long().to(train_config.device)\n",
                "    src_pos = torch.from_numpy(src_pos).long().to(train_config.device)\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        mel = model.forward(sequence, src_pos, alpha=alpha)\n",
                "    return mel[0].cpu().transpose(0, 1), mel.contiguous().transpose(1, 2)\n",
                "\n",
                "\n",
                "def get_data():\n",
                "    tests = [ \n",
                "        \"I am very happy to see you again!\",\n",
                "        \"Durian model is a very good speech synthesis!\",\n",
                "        \"When I was twenty, I fell in love with a girl.\",\n",
                "        \"I remove attention module in decoder and use average pooling to implement predicting r frames at once\",\n",
                "        \"You can not improve your past, but you can improve your future. Once time is wasted, life is wasted.\",\n",
                "        \"Death comes to all, but great achievements raise a monument which shall endure until the sun grows old.\"\n",
                "    ]\n",
                "    data_list = list(text_to_sequence(test, train_config.text_cleaners) for test in tests)\n",
                "\n",
                "    return data_list\n",
                "\n",
                "data_list = get_data()\n",
                "for speed in [0.8, 1., 1.3]:\n",
                "    for i, phn in tqdm(enumerate(data_list)):\n",
                "        mel, mel_cuda = synthesis(model, phn, speed)\n",
                "        \n",
                "        os.makedirs(\"results\", exist_ok=True)\n",
                "        \n",
                "        audio.tools.inv_mel_spec(\n",
                "            mel, f\"results/s={speed}_{i}.wav\"\n",
                "        )\n",
                "        \n",
                "        waveglow.inference.inference(\n",
                "            mel_cuda, WaveGlow,\n",
                "            f\"results/s={speed}_{i}_waveglow.wav\"\n",
                "        )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "display.Audio(\"results/s=0.8_5_waveglow.wav\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.13 ('base')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.9.13"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "161c945532039f7d57aa33e4253d854ac273b60397325c019a7bd57c2c7e143b"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
